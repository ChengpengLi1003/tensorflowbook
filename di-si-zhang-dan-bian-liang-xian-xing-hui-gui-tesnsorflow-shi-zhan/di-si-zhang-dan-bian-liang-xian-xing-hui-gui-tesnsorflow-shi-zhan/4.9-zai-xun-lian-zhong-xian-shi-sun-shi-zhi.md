# 4.9 在训练中显示损失值

为了使训练时结果更加直观，我们将每一轮的训练损失值都显示出来，只需在之前的训练的代码中加入几行显示代码，显示效果如图4-18所示。

```python
# 开始训练，轮数为 epoch，采用SGD随机梯度下降优化方法
step = 0   # 记录训练步数
loss_list = []   # 用于保存loss值的列表

for epoch in range(train_epochs):
    for xs,ys in zip(x_data, y_data):
        _, loss=sess.run([optimizer,loss_function], feed_dict={x: xs, y: ys}) 
        
        # 显示损失值 loss
        # display_step：控制报告的粒度
        # 例如，如果 display_step 设为 2 ，则将每训练2个样本输出一次损失值
        # 与超参数不同，修改 display_step 不会更改模型所学习的规律
        loss_list.append(loss)
        step=step+1
        if step % display_step == 0:
            print("Train Epoch:", '%02d' % (epoch+1), "Step: %03d" % (step),"loss=", \
                  "{:.9f}".format(loss))
        
    b0temp=b.eval(session=sess)
    w0temp=w.eval(session=sess)
    plt.plot (x_data, w0temp * x_data + b0temp  )# 画图
```

![&#x56FE; 4-18](../../.gitbook/assets/tu-pian-2%20%284%29.png)

