# 4.6 学习率

那么沿着负梯度方向进行下一步探索，前进多少才合适呢？这时我们就要引入学习率的概念了。

#### 4.6.1 学习率的概念

用梯度乘以一个称为学习率（有时也称为步长）的标量，以确定下一个点的位置。例如：如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。

所以学习率是指导我们该如何通过损失函数的梯度调整网络权重的一个参数（也成为超参数）。学习率越低，损失函数的变化速度就越慢。

#### 4.6.2 学习率的选择

![&#x56FE;4-10 &#x5B66;&#x4E60;&#x7387;&#x7684;&#x9009;&#x62E9;](../../.gitbook/assets/2%20%281%29.PNG)

如图4-10所示，如果学习率选择过小，损失函数优化速度极慢，训练的实践会非常长。而如果学习率选择过小，容易越过损失函数的最低点，无法拟合。

![&#x56FE;4-11](../../.gitbook/assets/bu-huo%20%286%29.PNG)

所以选择学习率（乃至所有超参数的选择）就像一个和面的过程，水放的太多容易太稀，水放的太少没黏性。

